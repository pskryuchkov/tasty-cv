{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc8ee24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:17.470302Z",
     "iopub.status.busy": "2025-07-16T09:52:17.469912Z",
     "iopub.status.idle": "2025-07-16T09:52:21.937516Z",
     "shell.execute_reply": "2025-07-16T09:52:21.935572Z"
    },
    "papermill": {
     "duration": 4.474113,
     "end_time": "2025-07-16T09:52:21.939296",
     "exception": false,
     "start_time": "2025-07-16T09:52:17.465183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# docs: https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "# dependencies: pip install tqdm pandas pillow torch torchvision\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b462e28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:21.947102Z",
     "iopub.status.busy": "2025-07-16T09:52:21.946622Z",
     "iopub.status.idle": "2025-07-16T09:52:21.952070Z",
     "shell.execute_reply": "2025-07-16T09:52:21.950800Z"
    },
    "papermill": {
     "duration": 0.010964,
     "end_time": "2025-07-16T09:52:21.953584",
     "exception": false,
     "start_time": "2025-07-16T09:52:21.942620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ea5b7",
   "metadata": {
    "papermill": {
     "duration": 0.00244,
     "end_time": "2025-07-16T09:52:21.959010",
     "exception": false,
     "start_time": "2025-07-16T09:52:21.956570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b597b3de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:21.965541Z",
     "iopub.status.busy": "2025-07-16T09:52:21.965160Z",
     "iopub.status.idle": "2025-07-16T09:52:21.971670Z",
     "shell.execute_reply": "2025-07-16T09:52:21.970526Z"
    },
    "papermill": {
     "duration": 0.011588,
     "end_time": "2025-07-16T09:52:21.973118",
     "exception": false,
     "start_time": "2025-07-16T09:52:21.961530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATSET_FILE = \"../../data/oid/parquets/train_remote.parquet\"\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "BATCH_SIZE = 8\n",
    "TRAIN_HEAD_ONLY = False\n",
    "\n",
    "START_EPOCH = 0\n",
    "NUM_EPOCHS = 10\n",
    "TQDM_ITERS = 100\n",
    "TQDM_INTERVAL = 60\n",
    "\n",
    "TEST_RUN = False\n",
    "TEST_SIZE = 0.1\n",
    "PRECISION = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d23e7b",
   "metadata": {
    "papermill": {
     "duration": 0.002483,
     "end_time": "2025-07-16T09:52:21.978077",
     "exception": false,
     "start_time": "2025-07-16T09:52:21.975594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6600ab73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:21.984255Z",
     "iopub.status.busy": "2025-07-16T09:52:21.983930Z",
     "iopub.status.idle": "2025-07-16T09:52:21.993517Z",
     "shell.execute_reply": "2025-07-16T09:52:21.992508Z"
    },
    "papermill": {
     "duration": 0.014493,
     "end_time": "2025-07-16T09:52:21.995016",
     "exception": false,
     "start_time": "2025-07-16T09:52:21.980523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DetectionDataset(Dataset):\n",
    "    def __init__(self, df, device):\n",
    "        self.df = df\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def resize(\n",
    "        self, image: Image.Image, min_size: int = 800, max_size: int = 1333\n",
    "    ) -> Image.Image:\n",
    "        orig_width, orig_height = image.size\n",
    "        min_orig_size = float(min((orig_width, orig_height)))\n",
    "        max_orig_size = float(max((orig_width, orig_height)))\n",
    "\n",
    "        scale = min_size / min_orig_size\n",
    "        if max_orig_size * scale > max_size:\n",
    "            scale = max_size / max_orig_size\n",
    "\n",
    "        new_width = int(round(orig_width * scale))\n",
    "        new_height = int(round(orig_height * scale))\n",
    "\n",
    "        return F.resize(image, (new_height, new_width))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        image = self.resize(Image.open(row[\"image_path\"]))\n",
    "        width, height = image.size\n",
    "        image = self.transform(image.convert(\"RGB\")).to(self.device)\n",
    "        boxes = (\n",
    "            torch.Tensor(\n",
    "                np.array([width, height, width, height]) * np.array(row[\"bbox\"])\n",
    "            )\n",
    "            .reshape(-1, 4)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        labels = torch.tensor([row[\"class\"]], dtype=torch.int64).to(self.device)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dfde4d",
   "metadata": {
    "papermill": {
     "duration": 0.002398,
     "end_time": "2025-07-16T09:52:22.000185",
     "exception": false,
     "start_time": "2025-07-16T09:52:21.997787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f7fb58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:22.006971Z",
     "iopub.status.busy": "2025-07-16T09:52:22.006695Z",
     "iopub.status.idle": "2025-07-16T09:52:22.019830Z",
     "shell.execute_reply": "2025-07-16T09:52:22.018770Z"
    },
    "papermill": {
     "duration": 0.018746,
     "end_time": "2025-07-16T09:52:22.021675",
     "exception": false,
     "start_time": "2025-07-16T09:52:22.002929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_intersection(box1, box2):\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "\n",
    "    x_left = max(x1_1, x1_2)\n",
    "    y_top = max(y1_1, y1_2)\n",
    "    x_right = min(x2_1, x2_2)\n",
    "    y_bottom = min(y2_1, y2_2)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "\n",
    "    iou_value = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "    return iou_value\n",
    "\n",
    "\n",
    "def eval_segmentation(model, dataloader):\n",
    "    boxes_true, boxes_pred = [], []\n",
    "    labels_true, labels_pred = [], []\n",
    "    for images, targets in dataloader:\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        target = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "            predict = model(images)\n",
    "\n",
    "        for j in range(len(predict)):\n",
    "            target_boxes, pred_boxes = target[j][\"boxes\"], predict[j][\"boxes\"]\n",
    "            boxes_true.append(target_boxes[0].to(\"cpu\").numpy())\n",
    "            boxes_pred.append(\n",
    "                pred_boxes[0].to(\"cpu\").numpy() if len(pred_boxes) else None\n",
    "            )\n",
    "\n",
    "            target_label, pred_label = target[j][\"labels\"], predict[j][\"labels\"]\n",
    "            labels_true.append(target_label[0].to(\"cpu\"))\n",
    "            labels_pred.append(pred_label[0].to(\"cpu\") if len(pred_label) else -1)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics[\"intersection\"] = float(\n",
    "        np.mean(\n",
    "            [\n",
    "                calc_intersection(box_true, box_pred) if box_pred is not None else 0\n",
    "                for box_true, box_pred in zip(boxes_true, boxes_pred)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    metrics[\"precision\"] = precision_score(\n",
    "        labels_true, labels_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    metrics[\"recall\"] = recall_score(\n",
    "        labels_true, labels_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    metrics[\"f1\"] = f1_score(labels_true, labels_pred, average=\"macro\", zero_division=0)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5defdaac",
   "metadata": {
    "papermill": {
     "duration": 0.002588,
     "end_time": "2025-07-16T09:52:22.026966",
     "exception": false,
     "start_time": "2025-07-16T09:52:22.024378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe1a11d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:22.033323Z",
     "iopub.status.busy": "2025-07-16T09:52:22.032995Z",
     "iopub.status.idle": "2025-07-16T09:52:22.074543Z",
     "shell.execute_reply": "2025-07-16T09:52:22.073413Z"
    },
    "papermill": {
     "duration": 0.04644,
     "end_time": "2025-07-16T09:52:22.075960",
     "exception": false,
     "start_time": "2025-07-16T09:52:22.029520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load parquet\n",
    "df = pd.read_parquet(DATSET_FILE)\n",
    "train_df, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=0)\n",
    "train_dataset, test_dataset = DetectionDataset(train_df, DEVICE), DetectionDataset(\n",
    "    test_df, DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01239746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:22.082915Z",
     "iopub.status.busy": "2025-07-16T09:52:22.082635Z",
     "iopub.status.idle": "2025-07-16T09:52:22.088276Z",
     "shell.execute_reply": "2025-07-16T09:52:22.087266Z"
    },
    "papermill": {
     "duration": 0.011137,
     "end_time": "2025-07-16T09:52:22.089987",
     "exception": false,
     "start_time": "2025-07-16T09:52:22.078850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db4fd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:22.097038Z",
     "iopub.status.busy": "2025-07-16T09:52:22.096771Z",
     "iopub.status.idle": "2025-07-16T09:52:23.738063Z",
     "shell.execute_reply": "2025-07-16T09:52:23.736851Z"
    },
    "papermill": {
     "duration": 1.647065,
     "end_time": "2025-07-16T09:52:23.740091",
     "exception": false,
     "start_time": "2025-07-16T09:52:22.093026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=423, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=1692, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "num_classes = df[\"class\"].max() + 1\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = (\n",
    "    torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    ")\n",
    "if START_EPOCH > 0:\n",
    "    model.load_state_dict(torch.load(f\"fasterrcnn{START_EPOCH}e.pth\"))\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5493c899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:23.747798Z",
     "iopub.status.busy": "2025-07-16T09:52:23.747506Z",
     "iopub.status.idle": "2025-07-16T09:52:23.753508Z",
     "shell.execute_reply": "2025-07-16T09:52:23.752519Z"
    },
    "papermill": {
     "duration": 0.011536,
     "end_time": "2025-07-16T09:52:23.754963",
     "exception": false,
     "start_time": "2025-07-16T09:52:23.743427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "if TRAIN_HEAD_ONLY:\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.001, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e749c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:52:23.761978Z",
     "iopub.status.busy": "2025-07-16T09:52:23.761712Z",
     "iopub.status.idle": "2025-07-16T11:15:01.637322Z",
     "shell.execute_reply": "2025-07-16T11:15:01.635065Z"
    },
    "papermill": {
     "duration": 4957.8819,
     "end_time": "2025-07-16T11:15:01.639828",
     "exception": false,
     "start_time": "2025-07-16T09:52:23.757928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [08:02<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 Loss: 0.2 Intersection: 0.0 Precision: 0.0 Recall: 0.0 F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [07:49<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 Loss: 0.218 Intersection: 0.353 Precision: 0.002 Recall: 0.014 F1: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [07:34<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2 Loss: 0.268 Intersection: 0.383 Precision: 0.002 Recall: 0.015 F1: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [07:27<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3 Loss: 0.397 Intersection: 0.376 Precision: 0.004 Recall: 0.015 F1: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [07:16<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4 Loss: 0.305 Intersection: 0.382 Precision: 0.004 Recall: 0.016 F1: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [07:46<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5 Loss: 0.213 Intersection: 0.395 Precision: 0.022 Recall: 0.026 F1: 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [07:43<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6 Loss: 0.268 Intersection: 0.4 Precision: 0.018 Recall: 0.031 F1: 0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [08:02<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7 Loss: 0.328 Intersection: 0.412 Precision: 0.019 Recall: 0.031 F1: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [07:39<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8 Loss: 0.204 Intersection: 0.407 Precision: 0.025 Recall: 0.04 F1: 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 748/748 [07:15<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9 Loss: 0.259 Intersection: 0.392 Precision: 0.025 Recall: 0.052 F1: 0.03\n"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "for epoch in range(START_EPOCH, NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for images, targets in tqdm(\n",
    "        train_loader, miniters=TQDM_ITERS, mininterval=TQDM_INTERVAL\n",
    "    ):\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    metrics = eval_segmentation(model, test_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch #{epoch} Loss: {round(losses.item(), PRECISION)} \"\n",
    "        + f\"Intersection: {round(metrics['intersection'], PRECISION)} \"\n",
    "        + f\"Precision: {round(metrics['precision'], PRECISION)} \"\n",
    "        + f\"Recall: {round(metrics['recall'], PRECISION)} \"\n",
    "        + f\"F1: {round(metrics['f1'], PRECISION)}\"\n",
    "    )\n",
    "    torch.save(model.state_dict(), f\"fasterrcnn{epoch}e.pth\")\n",
    "\n",
    "    if TEST_RUN:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4968.537624,
   "end_time": "2025-07-16T11:15:04.819930",
   "environment_variables": {},
   "exception": null,
   "input_path": "train_detection.ipynb",
   "output_path": "train_out1.ipynb",
   "parameters": {},
   "start_time": "2025-07-16T09:52:16.282306",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}