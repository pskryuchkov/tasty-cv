{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detection\n",
    "# https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "# https://chatgpt.com/c/67fa0c48-7acc-8003-bb1b-966899fcc1a4\n",
    "# pip install tqdm pandas pillow torch torchvision\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'rice',\n",
       " 2: 'eels on rice',\n",
       " 3: 'pilaf',\n",
       " 4: \"chicken-'n'-egg on rice\",\n",
       " 5: 'pork cutlet on rice',\n",
       " 6: 'beef curry',\n",
       " 7: 'sushi',\n",
       " 8: 'chicken rice',\n",
       " 9: 'fried rice',\n",
       " 10: 'tempura bowl',\n",
       " 11: 'bibimbap',\n",
       " 12: 'toast',\n",
       " 13: 'croissant',\n",
       " 14: 'roll bread',\n",
       " 15: 'raisin bread',\n",
       " 16: 'chip butty',\n",
       " 17: 'hamburger',\n",
       " 18: 'pizza',\n",
       " 19: 'sandwiches',\n",
       " 20: 'udon noodle',\n",
       " 21: 'tempura udon',\n",
       " 22: 'soba noodle',\n",
       " 23: 'ramen noodle',\n",
       " 24: 'beef noodle',\n",
       " 25: 'tensin noodle',\n",
       " 26: 'fried noodle',\n",
       " 27: 'spaghetti',\n",
       " 28: 'Japanese-style pancake',\n",
       " 29: 'takoyaki',\n",
       " 30: 'gratin',\n",
       " 31: 'sauteed vegetables',\n",
       " 32: 'croquette',\n",
       " 33: 'grilled eggplant',\n",
       " 34: 'sauteed spinach',\n",
       " 35: 'vegetable tempura',\n",
       " 36: 'miso soup',\n",
       " 37: 'potage',\n",
       " 38: 'sausage',\n",
       " 39: 'oden',\n",
       " 40: 'omelet',\n",
       " 41: 'ganmodoki',\n",
       " 42: 'jiaozi',\n",
       " 43: 'stew',\n",
       " 44: 'teriyaki grilled fish',\n",
       " 45: 'fried fish',\n",
       " 46: 'grilled salmon',\n",
       " 47: 'salmon meuniere',\n",
       " 48: 'sashimi',\n",
       " 49: 'grilled pacific saury',\n",
       " 50: 'sukiyaki',\n",
       " 51: 'sweet and sour pork',\n",
       " 52: 'lightly roasted fish',\n",
       " 53: 'steamed egg hotchpotch',\n",
       " 54: 'tempura',\n",
       " 55: 'fried chicken',\n",
       " 56: 'sirloin cutlet',\n",
       " 57: 'nanbanzuke',\n",
       " 58: 'boiled fish',\n",
       " 59: 'seasoned beef with potatoes',\n",
       " 60: 'hambarg steak',\n",
       " 61: 'steak',\n",
       " 62: 'dried fish',\n",
       " 63: 'ginger pork saute',\n",
       " 64: 'spicy chili-flavored tofu',\n",
       " 65: 'yakitori',\n",
       " 66: 'cabbage roll',\n",
       " 67: 'omelet',\n",
       " 68: 'egg sunny-side up',\n",
       " 69: 'natto',\n",
       " 70: 'cold tofu',\n",
       " 71: 'egg roll',\n",
       " 72: 'chilled noodle',\n",
       " 73: 'stir-fried beef and peppers',\n",
       " 74: 'simmered pork',\n",
       " 75: 'boiled chicken and vegetables',\n",
       " 76: 'sashimi bowl',\n",
       " 77: 'sushi bowl',\n",
       " 78: 'fish-shaped pancake with bean jam',\n",
       " 79: 'shrimp with chill source',\n",
       " 80: 'roast chicken',\n",
       " 81: 'steamed meat dumpling',\n",
       " 82: 'omelet with fried rice',\n",
       " 83: 'cutlet curry',\n",
       " 84: 'spaghetti meat sauce',\n",
       " 85: 'fried shrimp',\n",
       " 86: 'potato salad',\n",
       " 87: 'green salad',\n",
       " 88: 'macaroni salad',\n",
       " 89: 'Japanese tofu and vegetable chowder',\n",
       " 90: 'pork miso soup',\n",
       " 91: 'chinese soup',\n",
       " 92: 'beef bowl',\n",
       " 93: 'kinpira-style sauteed burdock',\n",
       " 94: 'rice ball',\n",
       " 95: 'pizza toast',\n",
       " 96: 'dipping noodles',\n",
       " 97: 'hot dog',\n",
       " 98: 'french fries',\n",
       " 99: 'mixed rice',\n",
       " 100: 'goya chanpuru',\n",
       " 101: 'green curry',\n",
       " 102: 'okinawa soba',\n",
       " 103: 'mango pudding',\n",
       " 104: 'almond jelly',\n",
       " 105: 'jjigae',\n",
       " 106: 'dak galbi',\n",
       " 107: 'dry curry',\n",
       " 108: 'kamameshi',\n",
       " 109: 'rice vermicelli',\n",
       " 110: 'paella',\n",
       " 111: 'tanmen',\n",
       " 112: 'kushikatu',\n",
       " 113: 'yellow curry',\n",
       " 114: 'pancake',\n",
       " 115: 'champon',\n",
       " 116: 'crape',\n",
       " 117: 'tiramisu',\n",
       " 118: 'waffle',\n",
       " 119: 'rare cheese cake',\n",
       " 120: 'shortcake',\n",
       " 121: 'chop suey',\n",
       " 122: 'twice cooked pork',\n",
       " 123: 'mushroom risotto',\n",
       " 124: 'samul',\n",
       " 125: 'zoni',\n",
       " 126: 'french toast',\n",
       " 127: 'fine white noodles',\n",
       " 128: 'minestrone',\n",
       " 129: 'pot au feu',\n",
       " 130: 'chicken nugget',\n",
       " 131: 'namero',\n",
       " 132: 'french bread',\n",
       " 133: 'rice gruel',\n",
       " 134: 'broiled eel bowl',\n",
       " 135: 'clear soup',\n",
       " 136: 'yudofu',\n",
       " 137: 'mozuku',\n",
       " 138: 'inarizushi',\n",
       " 139: 'pork loin cutlet',\n",
       " 140: 'pork fillet cutlet',\n",
       " 141: 'chicken cutlet',\n",
       " 142: 'ham cutlet',\n",
       " 143: 'minced meat cutlet',\n",
       " 144: 'thinly sliced raw horsemeat',\n",
       " 145: 'bagel',\n",
       " 146: 'scone',\n",
       " 147: 'tortilla',\n",
       " 148: 'tacos',\n",
       " 149: 'nachos',\n",
       " 150: 'meat loaf',\n",
       " 151: 'scrambled egg',\n",
       " 152: 'rice gratin',\n",
       " 153: 'lasagna',\n",
       " 154: 'Caesar salad',\n",
       " 155: 'oatmeal',\n",
       " 156: 'fried pork dumplings served in soup',\n",
       " 157: 'oshiruko',\n",
       " 158: 'muffin',\n",
       " 159: 'popcorn',\n",
       " 160: 'cream puff',\n",
       " 161: 'doughnut',\n",
       " 162: 'apple pie',\n",
       " 163: 'parfait',\n",
       " 164: 'fried pork in scoop',\n",
       " 165: 'lamb kebabs',\n",
       " 166: 'dish consisting of stir-fried potato, eggplant and green pepper',\n",
       " 167: 'roast duck',\n",
       " 168: 'hot pot',\n",
       " 169: 'pork belly',\n",
       " 170: 'xiao long bao',\n",
       " 171: 'moon cake',\n",
       " 172: 'custard tart',\n",
       " 173: 'beef noodle soup',\n",
       " 174: 'pork cutlet',\n",
       " 175: 'minced pork rice',\n",
       " 176: 'fish ball soup',\n",
       " 177: 'oyster omelette',\n",
       " 178: 'glutinous oil rice',\n",
       " 179: 'trunip pudding',\n",
       " 180: 'stinky tofu',\n",
       " 181: 'lemon fig jelly',\n",
       " 182: 'khao soi',\n",
       " 183: 'Sour prawn soup',\n",
       " 184: 'Thai papaya salad',\n",
       " 185: 'boned, sliced Hainan-style chicken with marinated rice',\n",
       " 186: 'hot and sour, fish and vegetable ragout',\n",
       " 187: 'stir-fried mixed vegetables',\n",
       " 188: 'beef in oyster sauce',\n",
       " 189: 'pork satay',\n",
       " 190: 'spicy chicken salad',\n",
       " 191: 'noodles with fish curry',\n",
       " 192: 'Pork Sticky Noodles',\n",
       " 193: 'Pork with lemon',\n",
       " 194: 'stewed pork leg',\n",
       " 195: 'charcoal-boiled pork neck',\n",
       " 196: 'fried mussel pancakes',\n",
       " 197: 'Deep Fried Chicken Wing',\n",
       " 198: 'Barbecued red pork in sauce with rice',\n",
       " 199: 'Rice with roast duck',\n",
       " 200: 'Rice crispy pork',\n",
       " 201: 'Wonton soup',\n",
       " 202: 'Chicken Rice Curry With Coconut',\n",
       " 203: 'Crispy Noodles',\n",
       " 204: 'Egg Noodle In Chicken Yellow Curry',\n",
       " 205: 'coconut milk soup',\n",
       " 206: 'pho',\n",
       " 207: 'Hue beef rice vermicelli soup',\n",
       " 208: 'Vermicelli noodles with snails',\n",
       " 209: 'Fried spring rolls',\n",
       " 210: 'Steamed rice roll',\n",
       " 211: 'Shrimp patties',\n",
       " 212: 'ball shaped bun with pork',\n",
       " 213: 'Coconut milk-flavored crepes with shrimp and beef',\n",
       " 214: 'Small steamed savory rice pancake',\n",
       " 215: 'Glutinous Rice Balls',\n",
       " 216: 'loco moco',\n",
       " 217: 'haupia',\n",
       " 218: 'malasada',\n",
       " 219: 'laulau',\n",
       " 220: 'spam musubi',\n",
       " 221: 'oxtail soup',\n",
       " 222: 'adobo',\n",
       " 223: 'lumpia',\n",
       " 224: 'brownie',\n",
       " 225: 'churro',\n",
       " 226: 'jambalaya',\n",
       " 227: 'nasi goreng',\n",
       " 228: 'ayam goreng',\n",
       " 229: 'ayam bakar',\n",
       " 230: 'bubur ayam',\n",
       " 231: 'gulai',\n",
       " 232: 'laksa',\n",
       " 233: 'mie ayam',\n",
       " 234: 'mie goreng',\n",
       " 235: 'nasi campur',\n",
       " 236: 'nasi padang',\n",
       " 237: 'nasi uduk',\n",
       " 238: 'babi guling',\n",
       " 239: 'kaya toast',\n",
       " 240: 'bak kut teh',\n",
       " 241: 'curry puff',\n",
       " 242: 'chow mein',\n",
       " 243: 'zha jiang mian',\n",
       " 244: 'kung pao chicken',\n",
       " 245: 'crullers',\n",
       " 246: 'eggplant with garlic sauce',\n",
       " 247: 'three cup chicken',\n",
       " 248: 'bean curd family style',\n",
       " 249: 'salt & pepper fried shrimp with shell',\n",
       " 250: 'baked salmon',\n",
       " 251: 'braised pork meat ball with napa cabbage',\n",
       " 252: 'winter melon soup',\n",
       " 253: 'steamed spareribs',\n",
       " 254: 'chinese pumpkin pie',\n",
       " 255: 'eight treasure rice',\n",
       " 256: 'hot & sour soup'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES_FN = \"../data/UECFOOD256/category.txt\"\n",
    "\n",
    "with open(CATEGORIES_FN, \"r\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "    id2name = {}\n",
    "    for i in range(1, len(data)):\n",
    "        category_id, category_name = data[i].split(\"\\t\")\n",
    "        label_id, name = int(category_id), category_name.strip()\n",
    "        id2name[label_id] = name\n",
    "\n",
    "id2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>image_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190485</td>\n",
       "      <td>[25, 1, 571, 398]</td>\n",
       "      <td>../data/UECFOOD256/135/190485.jpg</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89365</td>\n",
       "      <td>[29, 38, 406, 486]</td>\n",
       "      <td>../data/UECFOOD256/135/89365.jpg</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89147</td>\n",
       "      <td>[88, 49, 442, 325]</td>\n",
       "      <td>../data/UECFOOD256/135/89147.jpg</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89414</td>\n",
       "      <td>[10, 12, 493, 479]</td>\n",
       "      <td>../data/UECFOOD256/135/89414.jpg</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190903</td>\n",
       "      <td>[4, 70, 496, 472]</td>\n",
       "      <td>../data/UECFOOD256/135/190903.jpg</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31640</th>\n",
       "      <td>16769</td>\n",
       "      <td>[2, 3, 557, 414]</td>\n",
       "      <td>../data/UECFOOD256/25/16769.jpg</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31641</th>\n",
       "      <td>16770</td>\n",
       "      <td>[2, 46, 556, 375]</td>\n",
       "      <td>../data/UECFOOD256/25/16770.jpg</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31642</th>\n",
       "      <td>16773</td>\n",
       "      <td>[92, 41, 545, 472]</td>\n",
       "      <td>../data/UECFOOD256/25/16773.jpg</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31643</th>\n",
       "      <td>16781</td>\n",
       "      <td>[3, 8, 473, 355]</td>\n",
       "      <td>../data/UECFOOD256/25/16781.jpg</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31644</th>\n",
       "      <td>16791</td>\n",
       "      <td>[48, 36, 593, 453]</td>\n",
       "      <td>../data/UECFOOD256/25/16791.jpg</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31645 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                bbox                         image_path  class\n",
       "0        190485   [25, 1, 571, 398]  ../data/UECFOOD256/135/190485.jpg    135\n",
       "1         89365  [29, 38, 406, 486]   ../data/UECFOOD256/135/89365.jpg    135\n",
       "2         89147  [88, 49, 442, 325]   ../data/UECFOOD256/135/89147.jpg    135\n",
       "3         89414  [10, 12, 493, 479]   ../data/UECFOOD256/135/89414.jpg    135\n",
       "4        190903   [4, 70, 496, 472]  ../data/UECFOOD256/135/190903.jpg    135\n",
       "...         ...                 ...                                ...    ...\n",
       "31640     16769    [2, 3, 557, 414]    ../data/UECFOOD256/25/16769.jpg     25\n",
       "31641     16770   [2, 46, 556, 375]    ../data/UECFOOD256/25/16770.jpg     25\n",
       "31642     16773  [92, 41, 545, 472]    ../data/UECFOOD256/25/16773.jpg     25\n",
       "31643     16781    [3, 8, 473, 355]    ../data/UECFOOD256/25/16781.jpg     25\n",
       "31644     16791  [48, 36, 593, 453]    ../data/UECFOOD256/25/16791.jpg     25\n",
       "\n",
       "[31645 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = glob(\"../data/UECFOOD256/*/*.jpg\")\n",
    "boxes_files = glob(\"../data/UECFOOD256/*/bb_info.txt\")\n",
    "\n",
    "\n",
    "ids, boxes = [], []\n",
    "for j in range(len(boxes_files)):\n",
    "    with open(boxes_files[j], \"r\") as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "        for i in range(1, len(data)):\n",
    "            line = list(map(int, data[i].split()))\n",
    "            ids.append(line[0])\n",
    "            boxes.append(line[1:5])\n",
    "\n",
    "\n",
    "id2path = {int(Path(image).stem): image for image in images}\n",
    "id2class = {int(Path(image).stem): int(Path(image).parts[-2]) for image in images}\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"image_id\": ids, \"bbox\": boxes})\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(lambda x: id2path.get(x))\n",
    "df[\"class\"] = df[\"image_id\"].apply(lambda x: id2class.get(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomObjectDetectionDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.df = df\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r = df.iloc[idx]\n",
    "\n",
    "        image = self.transform(Image.open(r[\"image_path\"]).convert(\"RGB\"))\n",
    "        boxes = torch.Tensor(r[\"bbox\"]).reshape(-1, 4)\n",
    "        labels = torch.tensor([r[\"class\"]], dtype=torch.int64)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "device = \"cpu\"\n",
    "dataset = CustomObjectDetectionDataset()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.to(device)\n",
    "\n",
    "num_classes = df[\"class\"].max() + 1\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = (\n",
    "    torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/6329 [02:32<53:45:09, 30.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m     loss_dict = model(images, targets)\n\u001b[32m     13\u001b[39m     losses = \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict.values())\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mlosses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     optimizer.step()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses.item()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.2/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in tqdm(dataloader):\n",
    "\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch #{epoch} Loss: {losses.item()}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"fasterrcnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
